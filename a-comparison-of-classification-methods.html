<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.5 A Comparison of Classification Methods | Introduction to Statistical Learning Using R Book Club</title>
  <meta name="description" content="This is the product of the R4DS Online Learning Community’s Introduction to Statistical Learning Using R Book Club." />
  <meta name="generator" content="bookdown 0.25 and GitBook 2.6.7" />

  <meta property="og:title" content="4.5 A Comparison of Classification Methods | Introduction to Statistical Learning Using R Book Club" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is the product of the R4DS Online Learning Community’s Introduction to Statistical Learning Using R Book Club." />
  <meta name="github-repo" content="r4ds/bookclub-islr" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.5 A Comparison of Classification Methods | Introduction to Statistical Learning Using R Book Club" />
  
  <meta name="twitter:description" content="This is the product of the R4DS Online Learning Community’s Introduction to Statistical Learning Using R Book Club." />
  

<meta name="author" content="The R4DS Online Learning Community" />


<meta name="date" content="2022-04-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="generative-models-for-classification.html"/>
<link rel="next" href="summary-of-the-classification-methods.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistical Learning Using R Book Club</a></li>

<li class="divider"></li>
<li><a href="index.html#welcome">Welcome<span></span></a><ul>
<li><a href="book-club-meetings.html#book-club-meetings">Book club meetings<span></span></a></li>
<li><a href="st-edition-vs-2nd-edition.html#st-edition-vs-2nd-edition">1st edition vs 2nd edition<span></span></a></li>
<li><a href="pace.html#pace">Pace<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction<span></span></a><ul>
<li class="chapter" data-level="1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html"><i class="fa fa-check"></i><b>1.1</b> What is statistical learning?<span></span></a></li>
<li class="chapter" data-level="1.2" data-path="why-islr.html"><a href="why-islr.html"><i class="fa fa-check"></i><b>1.2</b> Why ISLR?<span></span></a></li>
<li class="chapter" data-level="1.3" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i><b>1.3</b> Notation<span></span></a></li>
<li class="chapter" data-level="1.4" data-path="what-have-we-gotten-ourselves-into.html"><a href="what-have-we-gotten-ourselves-into.html"><i class="fa fa-check"></i><b>1.4</b> What have we gotten ourselves into?<span></span></a></li>
<li class="chapter" data-level="1.5" data-path="wheres-the-data.html"><a href="wheres-the-data.html"><i class="fa fa-check"></i><b>1.5</b> Where’s the data?<span></span></a></li>
<li class="chapter" data-level="1.6" data-path="some-useful-resources.html"><a href="some-useful-resources.html"><i class="fa fa-check"></i><b>1.6</b> Some useful resources:<span></span></a></li>
<li class="chapter" data-level="1.7" data-path="what-is-covered-in-the-book.html"><a href="what-is-covered-in-the-book.html"><i class="fa fa-check"></i><b>1.7</b> What is covered in the book?<span></span></a></li>
<li class="chapter" data-level="1.8" data-path="how-is-the-book-divided.html"><a href="how-is-the-book-divided.html"><i class="fa fa-check"></i><b>1.8</b> How is the book divided?<span></span></a></li>
<li class="chapter" data-level="1.9" data-path="some-examples-of-the-problems-addressed-with-statistical-analysis.html"><a href="some-examples-of-the-problems-addressed-with-statistical-analysis.html"><i class="fa fa-check"></i><b>1.9</b> Some examples of the problems addressed with statistical analysis<span></span></a></li>
<li class="chapter" data-level="1.10" data-path="datasets-provided-in-the-islr2-package.html"><a href="datasets-provided-in-the-islr2-package.html"><i class="fa fa-check"></i><b>1.10</b> Datasets provided in the ISLR2 package<span></span></a><ul>
<li class="chapter" data-level="1.10.1" data-path="datasets-provided-in-the-islr2-package.html"><a href="datasets-provided-in-the-islr2-package.html#example-datasets"><i class="fa fa-check"></i><b>1.10.1</b> Example datasets<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="meeting-videos.html"><a href="meeting-videos.html"><i class="fa fa-check"></i><b>1.11</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="1.11.1" data-path="meeting-videos.html"><a href="meeting-videos.html#cohort-1"><i class="fa fa-check"></i><b>1.11.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="1.11.2" data-path="meeting-videos.html"><a href="meeting-videos.html#cohort-2"><i class="fa fa-check"></i><b>1.11.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="1.11.3" data-path="meeting-videos.html"><a href="meeting-videos.html#cohort-3"><i class="fa fa-check"></i><b>1.11.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="learning.html"><a href="learning.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning<span></span></a><ul>
<li class="chapter" data-level="2.1" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html"><i class="fa fa-check"></i><b>2.1</b> What is Statistical Learning?<span></span></a><ul>
<li class="chapter" data-level="2.1.1" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#why-estimate-f"><i class="fa fa-check"></i><b>2.1.1</b> Why Estimate <span class="math inline">\(f\)</span>?<span></span></a></li>
<li class="chapter" data-level="2.1.2" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#how-do-we-estimate-f"><i class="fa fa-check"></i><b>2.1.2</b> How do we estimate <span class="math inline">\(f\)</span>?<span></span></a></li>
<li class="chapter" data-level="2.1.3" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#prediction-accuracy-vs-model-interpretability"><i class="fa fa-check"></i><b>2.1.3</b> Prediction Accuracy vs Model Interpretability<span></span></a></li>
<li class="chapter" data-level="2.1.4" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#supervised-versus-unsupervised-learning"><i class="fa fa-check"></i><b>2.1.4</b> Supervised Versus Unsupervised Learning<span></span></a></li>
<li class="chapter" data-level="2.1.5" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#regression-versus-classification-problems"><i class="fa fa-check"></i><b>2.1.5</b> Regression Versus Classification Problems<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html"><i class="fa fa-check"></i><b>2.2</b> Assessing Model Accuracy<span></span></a><ul>
<li class="chapter" data-level="2.2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#measuring-quality-of-fit"><i class="fa fa-check"></i><b>2.2.1</b> Measuring Quality of Fit<span></span></a></li>
<li class="chapter" data-level="2.2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2.2</b> The Bias-Variance Trade-Off<span></span></a></li>
<li class="chapter" data-level="2.2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-classification-setting"><i class="fa fa-check"></i><b>2.2.3</b> The Classification Setting<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.3</b> Exercises<span></span></a></li>
<li class="chapter" data-level="2.4" data-path="meeting-videos-1.html"><a href="meeting-videos-1.html"><i class="fa fa-check"></i><b>2.4</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="2.4.1" data-path="meeting-videos-1.html"><a href="meeting-videos-1.html#cohort-1-1"><i class="fa fa-check"></i><b>2.4.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="2.4.2" data-path="meeting-videos-1.html"><a href="meeting-videos-1.html#cohort-2-1"><i class="fa fa-check"></i><b>2.4.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="2.4.3" data-path="meeting-videos-1.html"><a href="meeting-videos-1.html#cohort-3-1"><i class="fa fa-check"></i><b>2.4.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>3</b> Linear Regression<span></span></a><ul>
<li class="chapter" data-level="3.1" data-path="questions-to-answer.html"><a href="questions-to-answer.html"><i class="fa fa-check"></i><b>3.1</b> Questions to Answer<span></span></a></li>
<li class="chapter" data-level="3.2" data-path="simple-linear-regression-definition.html"><a href="simple-linear-regression-definition.html"><i class="fa fa-check"></i><b>3.2</b> Simple Linear Regression: Definition<span></span></a></li>
<li class="chapter" data-level="3.3" data-path="simple-linear-regression-visualization.html"><a href="simple-linear-regression-visualization.html"><i class="fa fa-check"></i><b>3.3</b> Simple Linear Regression: Visualization<span></span></a></li>
<li class="chapter" data-level="3.4" data-path="simple-linear-regression-math.html"><a href="simple-linear-regression-math.html"><i class="fa fa-check"></i><b>3.4</b> Simple Linear Regression: Math<span></span></a><ul>
<li class="chapter" data-level="3.4.1" data-path="simple-linear-regression-math.html"><a href="simple-linear-regression-math.html#visualization-of-fit"><i class="fa fa-check"></i><b>3.4.1</b> Visualization of Fit<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="assessing-accuracy-of-coefficient-estimates.html"><a href="assessing-accuracy-of-coefficient-estimates.html"><i class="fa fa-check"></i><b>3.5</b> Assessing Accuracy of Coefficient Estimates<span></span></a></li>
<li class="chapter" data-level="3.6" data-path="meeting-videos-2.html"><a href="meeting-videos-2.html"><i class="fa fa-check"></i><b>3.6</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="3.6.1" data-path="meeting-videos-2.html"><a href="meeting-videos-2.html#cohort-1-2"><i class="fa fa-check"></i><b>3.6.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="3.6.2" data-path="meeting-videos-2.html"><a href="meeting-videos-2.html#cohort-2-2"><i class="fa fa-check"></i><b>3.6.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="3.6.3" data-path="meeting-videos-2.html"><a href="meeting-videos-2.html#cohort-3-2"><i class="fa fa-check"></i><b>3.6.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>4</b> Classification<span></span></a><ul>
<li class="chapter" data-level="4.1" data-path="an-overview-of-classification.html"><a href="an-overview-of-classification.html"><i class="fa fa-check"></i><b>4.1</b> An Overview of Classification<span></span></a></li>
<li class="chapter" data-level="4.2" data-path="why-not-linear-regression.html"><a href="why-not-linear-regression.html"><i class="fa fa-check"></i><b>4.2</b> Why NOT Linear Regression?<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>4.3</b> Logistic Regression<span></span></a><ul>
<li class="chapter" data-level="4.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#the-logistic-model"><i class="fa fa-check"></i><b>4.3.1</b> The Logistic Model<span></span></a></li>
<li class="chapter" data-level="4.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#estimating-the-regression-coefficient"><i class="fa fa-check"></i><b>4.3.2</b> Estimating the Regression Coefficient<span></span></a></li>
<li class="chapter" data-level="4.3.3" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>4.3.3</b> Multiple Logistic Regression<span></span></a></li>
<li class="chapter" data-level="4.3.4" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>4.3.4</b> Multinomial Logistic Regression<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html"><i class="fa fa-check"></i><b>4.4</b> Generative Models for Classification<span></span></a></li>
<li class="chapter" data-level="4.5" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html"><i class="fa fa-check"></i><b>4.5</b> A Comparison of Classification Methods<span></span></a><ul>
<li class="chapter" data-level="4.5.1" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#linear-discriminant-analysis-for-p-1"><i class="fa fa-check"></i><b>4.5.1</b> Linear Discriminant Analysis for p = 1<span></span></a></li>
<li class="chapter" data-level="4.5.2" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#linear-discriminant-analysis-for-p-1-1"><i class="fa fa-check"></i><b>4.5.2</b> Linear Discriminant Analysis for p &gt; 1<span></span></a></li>
<li class="chapter" data-level="4.5.3" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#quadratic-discriminant-analysis-qda"><i class="fa fa-check"></i><b>4.5.3</b> Quadratic Discriminant Analysis (QDA)<span></span></a></li>
<li class="chapter" data-level="4.5.4" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#naive-bayes"><i class="fa fa-check"></i><b>4.5.4</b> Naive Bayes<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="summary-of-the-classification-methods.html"><a href="summary-of-the-classification-methods.html"><i class="fa fa-check"></i><b>4.6</b> Summary of the classification methods<span></span></a><ul>
<li class="chapter" data-level="4.6.1" data-path="summary-of-the-classification-methods.html"><a href="summary-of-the-classification-methods.html#an-analytical-comparison"><i class="fa fa-check"></i><b>4.6.1</b> An Analytical Comparison<span></span></a></li>
<li class="chapter" data-level="4.6.2" data-path="summary-of-the-classification-methods.html"><a href="summary-of-the-classification-methods.html#an-empirical-comparison"><i class="fa fa-check"></i><b>4.6.2</b> An Empirical Comparison<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>4.7</b> Generalized Linear Models<span></span></a></li>
<li class="chapter" data-level="4.8" data-path="linear-regression-with-count-data---negative-values.html"><a href="linear-regression-with-count-data---negative-values.html"><i class="fa fa-check"></i><b>4.8</b> Linear regression with count data - negative values<span></span></a></li>
<li class="chapter" data-level="4.9" data-path="linear-regression-with-count-data---heteroscedasticity.html"><a href="linear-regression-with-count-data---heteroscedasticity.html"><i class="fa fa-check"></i><b>4.9</b> Linear regression with count data - heteroscedasticity<span></span></a></li>
<li class="chapter" data-level="4.10" data-path="problems-with-linear-regression-of-count-data.html"><a href="problems-with-linear-regression-of-count-data.html"><i class="fa fa-check"></i><b>4.10</b> Problems with linear regression of count data<span></span></a></li>
<li class="chapter" data-level="4.11" data-path="poisson-distribution.html"><a href="poisson-distribution.html"><i class="fa fa-check"></i><b>4.11</b> Poisson distribution<span></span></a></li>
<li class="chapter" data-level="4.12" data-path="poisson-regression-model-mean-lambda.html"><a href="poisson-regression-model-mean-lambda.html"><i class="fa fa-check"></i><b>4.12</b> Poisson Regression Model mean (lambda)<span></span></a></li>
<li class="chapter" data-level="4.13" data-path="estimating-the-poisson-regression-parameters.html"><a href="estimating-the-poisson-regression-parameters.html"><i class="fa fa-check"></i><b>4.13</b> Estimating the Poisson Regression parameters<span></span></a></li>
<li class="chapter" data-level="4.14" data-path="interpreting-poisson-regression.html"><a href="interpreting-poisson-regression.html"><i class="fa fa-check"></i><b>4.14</b> Interpreting Poisson Regression<span></span></a></li>
<li class="chapter" data-level="4.15" data-path="advantages-of-poisson-regression.html"><a href="advantages-of-poisson-regression.html"><i class="fa fa-check"></i><b>4.15</b> Advantages of Poisson Regression<span></span></a></li>
<li class="chapter" data-level="4.16" data-path="generalized-linear-models-1.html"><a href="generalized-linear-models-1.html"><i class="fa fa-check"></i><b>4.16</b> Generalized Linear Models<span></span></a></li>
<li class="chapter" data-level="4.17" data-path="addendum---logistic-regression-assumptions.html"><a href="addendum---logistic-regression-assumptions.html"><i class="fa fa-check"></i><b>4.17</b> Addendum - Logistic Regression Assumptions<span></span></a></li>
<li class="chapter" data-level="4.18" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html"><i class="fa fa-check"></i><b>4.18</b> Lab: Classification Methods<span></span></a></li>
<li class="chapter" data-level="4.19" data-path="meeting-videos-3.html"><a href="meeting-videos-3.html"><i class="fa fa-check"></i><b>4.19</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="4.19.1" data-path="meeting-videos-3.html"><a href="meeting-videos-3.html#cohort-1-3"><i class="fa fa-check"></i><b>4.19.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="4.19.2" data-path="meeting-videos-3.html"><a href="meeting-videos-3.html#cohort-2-3"><i class="fa fa-check"></i><b>4.19.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="4.19.3" data-path="meeting-videos-3.html"><a href="meeting-videos-3.html#cohort-3-3"><i class="fa fa-check"></i><b>4.19.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods<span></span></a><ul>
<li class="chapter" data-level="5.1" data-path="validation-set-approach.html"><a href="validation-set-approach.html"><i class="fa fa-check"></i><b>5.1</b> Validation Set Approach<span></span></a></li>
<li class="chapter" data-level="5.2" data-path="validation-error-rate-varies-depending-on-data-set.html"><a href="validation-error-rate-varies-depending-on-data-set.html"><i class="fa fa-check"></i><b>5.2</b> Validation Error Rate Varies Depending on Data Set<span></span></a></li>
<li class="chapter" data-level="5.3" data-path="leave-one-out-cross-validation-loocv.html"><a href="leave-one-out-cross-validation-loocv.html"><i class="fa fa-check"></i><b>5.3</b> Leave-One-Out Cross-Validation (LOOCV)<span></span></a></li>
<li class="chapter" data-level="5.4" data-path="advantages-of-loocv-over-validation-set-approach.html"><a href="advantages-of-loocv-over-validation-set-approach.html"><i class="fa fa-check"></i><b>5.4</b> Advantages of LOOCV over Validation Set Approach<span></span></a></li>
<li class="chapter" data-level="5.5" data-path="k-fold-cross-validation.html"><a href="k-fold-cross-validation.html"><i class="fa fa-check"></i><b>5.5</b> k-fold Cross-Validation<span></span></a></li>
<li class="chapter" data-level="5.6" data-path="graphical-illustration-of-k-fold-approach.html"><a href="graphical-illustration-of-k-fold-approach.html"><i class="fa fa-check"></i><b>5.6</b> Graphical Illustration of k-fold Approach<span></span></a></li>
<li class="chapter" data-level="5.7" data-path="advantages-of-k-fold-cross-validation-over-loocv.html"><a href="advantages-of-k-fold-cross-validation-over-loocv.html"><i class="fa fa-check"></i><b>5.7</b> Advantages of k-fold Cross-Validation over LOOCV<span></span></a></li>
<li class="chapter" data-level="5.8" data-path="bias-variance-tradeoff-and-k-fold-cross-validation.html"><a href="bias-variance-tradeoff-and-k-fold-cross-validation.html"><i class="fa fa-check"></i><b>5.8</b> Bias-Variance Tradeoff and k-fold Cross-Validation<span></span></a></li>
<li class="chapter" data-level="5.9" data-path="cross-validation-on-classification-problems.html"><a href="cross-validation-on-classification-problems.html"><i class="fa fa-check"></i><b>5.9</b> Cross-Validation on Classification Problems<span></span></a></li>
<li class="chapter" data-level="5.10" data-path="logistic-polynomial-regression-bayes-decision-boundaries-and-k-fold-cross-validation.html"><a href="logistic-polynomial-regression-bayes-decision-boundaries-and-k-fold-cross-validation.html"><i class="fa fa-check"></i><b>5.10</b> Logistic Polynomial Regression, Bayes Decision Boundaries, and k-fold Cross Validation<span></span></a></li>
<li class="chapter" data-level="5.11" data-path="the-bootstrap.html"><a href="the-bootstrap.html"><i class="fa fa-check"></i><b>5.11</b> The Bootstrap<span></span></a></li>
<li class="chapter" data-level="5.12" data-path="population-distribution-compared-to-bootstrap-distribution.html"><a href="population-distribution-compared-to-bootstrap-distribution.html"><i class="fa fa-check"></i><b>5.12</b> Population Distribution Compared to Bootstrap Distribution<span></span></a></li>
<li class="chapter" data-level="5.13" data-path="bootstrap-standard-error.html"><a href="bootstrap-standard-error.html"><i class="fa fa-check"></i><b>5.13</b> Bootstrap Standard Error<span></span></a></li>
<li class="chapter" data-level="5.14" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html"><i class="fa fa-check"></i><b>5.14</b> Lab: Cross-Validation and the Bootstrap<span></span></a><ul>
<li class="chapter" data-level="5.14.1" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html#the-validation-set-approach"><i class="fa fa-check"></i><b>5.14.1</b> The Validation Set Approach<span></span></a></li>
<li class="chapter" data-level="5.14.2" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>5.14.2</b> Leave-One-Out Cross-Validation<span></span></a></li>
<li class="chapter" data-level="5.14.3" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html#k-fold-cross-validation-1"><i class="fa fa-check"></i><b>5.14.3</b> k-Fold Cross-Validation<span></span></a></li>
<li class="chapter" data-level="5.14.4" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html#the-bootstrap-1"><i class="fa fa-check"></i><b>5.14.4</b> The Bootstrap<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.15" data-path="meeting-videos-4.html"><a href="meeting-videos-4.html"><i class="fa fa-check"></i><b>5.15</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="5.15.1" data-path="meeting-videos-4.html"><a href="meeting-videos-4.html#cohort-1-4"><i class="fa fa-check"></i><b>5.15.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="5.15.2" data-path="meeting-videos-4.html"><a href="meeting-videos-4.html#cohort-2-4"><i class="fa fa-check"></i><b>5.15.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="5.15.3" data-path="meeting-videos-4.html"><a href="meeting-videos-4.html#cohort-3-4"><i class="fa fa-check"></i><b>5.15.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html"><i class="fa fa-check"></i><b>6</b> Linear Model Selection and Regularization<span></span></a><ul>
<li class="chapter" data-level="6.1" data-path="subset-selection.html"><a href="subset-selection.html"><i class="fa fa-check"></i><b>6.1</b> Subset Selection<span></span></a></li>
<li><a href="context-for-this-chapter.html#context-for-this-chapter">Context for This Chapter<span></span></a></li>
<li><a href="best-subset-selection-bss.html#best-subset-selection-bss">Best Subset Selection (BSS)<span></span></a></li>
<li><a href="bss-algorithm.html#bss-algorithm">BSS Algorithm<span></span></a></li>
<li><a href="bss-algorithm-1.html#bss-algorithm-1">BSS Algorithm<span></span></a></li>
<li><a href="behind-the-dots-bssing-islr2credit.html#behind-the-dots-bssing-islr2credit">Behind the dots, BSS’ing ISLR2::Credit<span></span></a></li>
<li><a href="best-subset-selection-bss-1.html#best-subset-selection-bss-1">Best Subset Selection (BSS)<span></span></a></li>
<li><a href="forward-stepwise-subset-selection-fsss.html#forward-stepwise-subset-selection-fsss">Forward Stepwise Subset Selection (FsSS)<span></span></a></li>
<li><a href="fsssing-islr2credit.html#fsssing-islr2credit">FsSS’ing ISLR2::Credit<span></span></a></li>
<li><a href="backward-stepwise-subset-selection-bsss.html#backward-stepwise-subset-selection-bsss">Backward Stepwise Subset Selection (BsSS)<span></span></a></li>
<li><a href="guided-searches.html#guided-searches">“Guided” searches<span></span></a></li>
<li><a href="choosing-the-best-model.html#choosing-the-best-model">Choosing the best model<span></span></a></li>
<li><a href="adjustment-methods.html#adjustment-methods">Adjustment Methods<span></span></a></li>
<li><a href="avoiding-adjustment-methods.html#avoiding-adjustment-methods">Avoiding Adjustment Methods<span></span></a></li>
<li><a href="various-variable-selection-methods-on-islr2credit.html#various-variable-selection-methods-on-islr2credit">Various variable selection methods on ISLR2::Credit<span></span></a></li>
<li><a href="in-conclusion.html#in-conclusion">In conclusion…<span></span></a></li>
<li class="chapter" data-level="6.2" data-path="shrinkage-methods.html"><a href="shrinkage-methods.html"><i class="fa fa-check"></i><b>6.2</b> Shrinkage Methods<span></span></a></li>
<li><a href="overview.html#overview">Overview<span></span></a></li>
<li><a href="ols-review.html#ols-review">OLS review<span></span></a></li>
<li><a href="ridge-regression.html#ridge-regression">Ridge Regression<span></span></a></li>
<li><a href="ridge-regression-visually.html#ridge-regression-visually">Ridge Regression, Visually<span></span></a></li>
<li><a href="ridge-good.html#ridge-good">Ridge, good?<span></span></a></li>
<li><a href="preprocessing.html#preprocessing">Preprocessing<span></span></a></li>
<li><a href="the-lasso.html#the-lasso">The Lasso<span></span></a></li>
<li><a href="justin-grimmer-homework.html#justin-grimmer-homework">Justin Grimmer Homework<span></span></a></li>
<li><a href="visualization-of-such-that-formulations.html#visualization-of-such-that-formulations">Visualization of “such that” formulations<span></span></a></li>
<li><a href="bayesian-interpretation.html#bayesian-interpretation">Bayesian Interpretation<span></span></a></li>
<li><a href="bayesian-interpretation-cont.html#bayesian-interpretation-cont">Bayesian Interpretation (cont)<span></span></a></li>
<li><a href="choosing-the-tuning-parameter.html#choosing-the-tuning-parameter">Choosing the tuning parameter<span></span></a></li>
<li><a href="tuning-lambda.html#tuning-lambda">Tuning <span class="math inline">\(\lambda\)</span><span></span></a></li>
<li class="chapter" data-level="6.3" data-path="dimension-reduction-methods.html"><a href="dimension-reduction-methods.html"><i class="fa fa-check"></i><b>6.3</b> Dimension Reduction Methods<span></span></a></li>
<li><a href="the-math.html#the-math">The Math<span></span></a></li>
<li><a href="principal-components-regression.html#principal-components-regression">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-1.html#principal-components-regression-1">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-2.html#principal-components-regression-2">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-3.html#principal-components-regression-3">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-4.html#principal-components-regression-4">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-5.html#principal-components-regression-5">Principal Components Regression<span></span></a></li>
<li><a href="partial-least-squares.html#partial-least-squares">Partial Least Squares<span></span></a></li>
<li class="chapter" data-level="6.4" data-path="considerations-in-high-dimensions.html"><a href="considerations-in-high-dimensions.html"><i class="fa fa-check"></i><b>6.4</b> Considerations in High Dimensions<span></span></a></li>
<li><a href="considerations-in-high-dimensions-1.html#considerations-in-high-dimensions-1">Considerations in High Dimensions<span></span></a></li>
<li><a href="lasso-etc-vs-dimensionality.html#lasso-etc-vs-dimensionality">Lasso (etc) vs Dimensionality<span></span></a></li>
<li class="chapter" data-level="6.5" data-path="meeting-videos-5.html"><a href="meeting-videos-5.html"><i class="fa fa-check"></i><b>6.5</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="6.5.1" data-path="meeting-videos-5.html"><a href="meeting-videos-5.html#cohort-1-5"><i class="fa fa-check"></i><b>6.5.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="6.5.2" data-path="meeting-videos-5.html"><a href="meeting-videos-5.html#cohort-2-5"><i class="fa fa-check"></i><b>6.5.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="6.5.3" data-path="meeting-videos-5.html"><a href="meeting-videos-5.html#cohort-3-5"><i class="fa fa-check"></i><b>6.5.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html"><i class="fa fa-check"></i><b>7</b> Moving Beyond Linearity<span></span></a><ul>
<li class="chapter" data-level="7.1" data-path="polynomial-and-step-regression.html"><a href="polynomial-and-step-regression.html"><i class="fa fa-check"></i><b>7.1</b> Polynomial and Step Regression<span></span></a></li>
<li class="chapter" data-level="7.2" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>7.2</b> Splines<span></span></a></li>
<li class="chapter" data-level="7.3" data-path="generalized-additive-models.html"><a href="generalized-additive-models.html"><i class="fa fa-check"></i><b>7.3</b> Generalized Additive Models<span></span></a></li>
<li class="chapter" data-level="7.4" data-path="meeting-videos-6.html"><a href="meeting-videos-6.html"><i class="fa fa-check"></i><b>7.4</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="7.4.1" data-path="meeting-videos-6.html"><a href="meeting-videos-6.html#cohort-1-6"><i class="fa fa-check"></i><b>7.4.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="7.4.2" data-path="meeting-videos-6.html"><a href="meeting-videos-6.html#cohort-2-6"><i class="fa fa-check"></i><b>7.4.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="7.4.3" data-path="meeting-videos-6.html"><a href="meeting-videos-6.html#cohort-3-6"><i class="fa fa-check"></i><b>7.4.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>8</b> Tree-Based Methods<span></span></a><ul>
<li class="chapter" data-level="8.1" data-path="decision-tree-terminology.html"><a href="decision-tree-terminology.html"><i class="fa fa-check"></i><b>8.1</b> Decision Tree Terminology<span></span></a></li>
<li class="chapter" data-level="8.2" data-path="decision-trees-classification-explained-statquest.html"><a href="decision-trees-classification-explained-statquest.html"><i class="fa fa-check"></i><b>8.2</b> Decision Trees (Classification) Explained (StatQuest)<span></span></a></li>
<li class="chapter" data-level="8.3" data-path="fitting-classification-trees.html"><a href="fitting-classification-trees.html"><i class="fa fa-check"></i><b>8.3</b> 8.1 Fitting Classification Trees<span></span></a></li>
<li class="chapter" data-level="8.4" data-path="exploratory-data-analysis-eda.html"><a href="exploratory-data-analysis-eda.html"><i class="fa fa-check"></i><b>8.4</b> Exploratory Data Analysis (EDA)<span></span></a></li>
<li class="chapter" data-level="8.5" data-path="correlation-analysis.html"><a href="correlation-analysis.html"><i class="fa fa-check"></i><b>8.5</b> Correlation Analysis<span></span></a></li>
<li class="chapter" data-level="8.6" data-path="build-a-model.html"><a href="build-a-model.html"><i class="fa fa-check"></i><b>8.6</b> Build a model<span></span></a></li>
<li class="chapter" data-level="8.7" data-path="visualize-our-decision-tree.html"><a href="visualize-our-decision-tree.html"><i class="fa fa-check"></i><b>8.7</b> Visualize our decision tree<span></span></a></li>
<li class="chapter" data-level="8.8" data-path="evaluate-the-model.html"><a href="evaluate-the-model.html"><i class="fa fa-check"></i><b>8.8</b> Evaluate the model<span></span></a></li>
<li class="chapter" data-level="8.9" data-path="tuning-the-model.html"><a href="tuning-the-model.html"><i class="fa fa-check"></i><b>8.9</b> Tuning the model<span></span></a></li>
<li class="chapter" data-level="8.10" data-path="evaluate-the-model-1.html"><a href="evaluate-the-model-1.html"><i class="fa fa-check"></i><b>8.10</b> Evaluate the model<span></span></a></li>
<li class="chapter" data-level="8.11" data-path="visualize-the-tuned-decision-tree-classification.html"><a href="visualize-the-tuned-decision-tree-classification.html"><i class="fa fa-check"></i><b>8.11</b> Visualize the tuned decision tree (classification)<span></span></a></li>
<li class="chapter" data-level="8.12" data-path="variable-importance.html"><a href="variable-importance.html"><i class="fa fa-check"></i><b>8.12</b> Variable importance<span></span></a></li>
<li class="chapter" data-level="8.13" data-path="final-evaluation.html"><a href="final-evaluation.html"><i class="fa fa-check"></i><b>8.13</b> Final evaluation<span></span></a></li>
<li class="chapter" data-level="8.14" data-path="fitting-regression-trees.html"><a href="fitting-regression-trees.html"><i class="fa fa-check"></i><b>8.14</b> 8.2 - Fitting Regression Trees<span></span></a></li>
<li class="chapter" data-level="8.15" data-path="decision-trees-regression-explained-statquest.html"><a href="decision-trees-regression-explained-statquest.html"><i class="fa fa-check"></i><b>8.15</b> Decision Trees (Regression) Explained (StatQuest)<span></span></a><ul>
<li class="chapter" data-level="8.15.1" data-path="decision-trees-regression-explained-statquest.html"><a href="decision-trees-regression-explained-statquest.html#eda"><i class="fa fa-check"></i><b>8.15.1</b> EDA<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.16" data-path="correlation-analysis-1.html"><a href="correlation-analysis-1.html"><i class="fa fa-check"></i><b>8.16</b> Correlation Analysis<span></span></a></li>
<li class="chapter" data-level="8.17" data-path="build-a-regression-tree.html"><a href="build-a-regression-tree.html"><i class="fa fa-check"></i><b>8.17</b> Build a regression tree<span></span></a></li>
<li class="chapter" data-level="8.18" data-path="visualize-our-decision-tree-1.html"><a href="visualize-our-decision-tree-1.html"><i class="fa fa-check"></i><b>8.18</b> Visualize our decision tree<span></span></a></li>
<li class="chapter" data-level="8.19" data-path="evaluate-the-model-2.html"><a href="evaluate-the-model-2.html"><i class="fa fa-check"></i><b>8.19</b> Evaluate the model<span></span></a></li>
<li class="chapter" data-level="8.20" data-path="tuning-the-regression-model.html"><a href="tuning-the-regression-model.html"><i class="fa fa-check"></i><b>8.20</b> Tuning the regression model<span></span></a></li>
<li class="chapter" data-level="8.21" data-path="evaluate-the-model-3.html"><a href="evaluate-the-model-3.html"><i class="fa fa-check"></i><b>8.21</b> Evaluate the model<span></span></a></li>
<li class="chapter" data-level="8.22" data-path="visualize-the-tuned-decision-tree-regression.html"><a href="visualize-the-tuned-decision-tree-regression.html"><i class="fa fa-check"></i><b>8.22</b> Visualize the tuned decision tree (regression)<span></span></a></li>
<li class="chapter" data-level="8.23" data-path="variable-importance-1.html"><a href="variable-importance-1.html"><i class="fa fa-check"></i><b>8.23</b> Variable importance<span></span></a></li>
<li class="chapter" data-level="8.24" data-path="final-evaluation-1.html"><a href="final-evaluation-1.html"><i class="fa fa-check"></i><b>8.24</b> Final evaluation<span></span></a></li>
<li class="chapter" data-level="8.25" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html"><i class="fa fa-check"></i><b>8.25</b> 8.3 - Bagging and Random Forests<span></span></a></li>
<li class="chapter" data-level="8.26" data-path="random-forest-diagram.html"><a href="random-forest-diagram.html"><i class="fa fa-check"></i><b>8.26</b> Random Forest Diagram<span></span></a></li>
<li class="chapter" data-level="8.27" data-path="example.html"><a href="example.html"><i class="fa fa-check"></i><b>8.27</b> Example<span></span></a></li>
<li class="chapter" data-level="8.28" data-path="evaluate-the-model-4.html"><a href="evaluate-the-model-4.html"><i class="fa fa-check"></i><b>8.28</b> Evaluate the model<span></span></a></li>
<li class="chapter" data-level="8.29" data-path="variable-importance-2.html"><a href="variable-importance-2.html"><i class="fa fa-check"></i><b>8.29</b> Variable importance<span></span></a></li>
<li class="chapter" data-level="8.30" data-path="random-forest-using-a-set-of-features-mtry.html"><a href="random-forest-using-a-set-of-features-mtry.html"><i class="fa fa-check"></i><b>8.30</b> Random Forest using a set of features (mtry)<span></span></a></li>
<li class="chapter" data-level="8.31" data-path="evaluate-the-model-5.html"><a href="evaluate-the-model-5.html"><i class="fa fa-check"></i><b>8.31</b> Evaluate the model<span></span></a></li>
<li class="chapter" data-level="8.32" data-path="variable-importance-3.html"><a href="variable-importance-3.html"><i class="fa fa-check"></i><b>8.32</b> Variable importance<span></span></a></li>
<li class="chapter" data-level="8.33" data-path="boosting.html"><a href="boosting.html"><i class="fa fa-check"></i><b>8.33</b> Boosting<span></span></a></li>
<li class="chapter" data-level="8.34" data-path="evaluate-the-model-6.html"><a href="evaluate-the-model-6.html"><i class="fa fa-check"></i><b>8.34</b> Evaluate the model<span></span></a></li>
<li class="chapter" data-level="8.35" data-path="tuning-the-xgboost-regression-model.html"><a href="tuning-the-xgboost-regression-model.html"><i class="fa fa-check"></i><b>8.35</b> Tuning the xgboost regression model<span></span></a></li>
<li class="chapter" data-level="8.36" data-path="grid-tuning-with-finetunerace_anova.html"><a href="grid-tuning-with-finetunerace_anova.html"><i class="fa fa-check"></i><b>8.36</b> Grid tuning with finetune::race_anova()<span></span></a></li>
<li class="chapter" data-level="8.37" data-path="evaluate-the-model-7.html"><a href="evaluate-the-model-7.html"><i class="fa fa-check"></i><b>8.37</b> Evaluate the model<span></span></a></li>
<li class="chapter" data-level="8.38" data-path="final-evauation.html"><a href="final-evauation.html"><i class="fa fa-check"></i><b>8.38</b> Final evauation<span></span></a></li>
<li class="chapter" data-level="8.39" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>8.39</b> Feature importance<span></span></a></li>
<li class="chapter" data-level="8.40" data-path="meeting-videos-7.html"><a href="meeting-videos-7.html"><i class="fa fa-check"></i><b>8.40</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="8.40.1" data-path="meeting-videos-7.html"><a href="meeting-videos-7.html#cohort-1-7"><i class="fa fa-check"></i><b>8.40.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="8.40.2" data-path="meeting-videos-7.html"><a href="meeting-videos-7.html#cohort-2-7"><i class="fa fa-check"></i><b>8.40.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="8.40.3" data-path="meeting-videos-7.html"><a href="meeting-videos-7.html#cohort-3-7"><i class="fa fa-check"></i><b>8.40.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>9</b> Support Vector Machines<span></span></a><ul>
<li class="chapter" data-level="9.1" data-path="maximal-margin-classifier-hyperplanes.html"><a href="maximal-margin-classifier-hyperplanes.html"><i class="fa fa-check"></i><b>9.1</b> Maximal Margin Classifier &amp; Hyperplanes<span></span></a></li>
<li class="chapter" data-level="9.2" data-path="using-a-separating-hyperplane-to-classify.html"><a href="using-a-separating-hyperplane-to-classify.html"><i class="fa fa-check"></i><b>9.2</b> Using a Separating Hyperplane to Classify<span></span></a></li>
<li class="chapter" data-level="9.3" data-path="visual-example-of-using-a-hyperplane-to-classify.html"><a href="visual-example-of-using-a-hyperplane-to-classify.html"><i class="fa fa-check"></i><b>9.3</b> Visual Example of Using a Hyperplane to Classify<span></span></a></li>
<li class="chapter" data-level="9.4" data-path="maximal-margin-classifier.html"><a href="maximal-margin-classifier.html"><i class="fa fa-check"></i><b>9.4</b> Maximal Margin Classifier<span></span></a></li>
<li class="chapter" data-level="9.5" data-path="visual-representation-of-maximal-margin-classifier.html"><a href="visual-representation-of-maximal-margin-classifier.html"><i class="fa fa-check"></i><b>9.5</b> Visual Representation of Maximal Margin Classifier<span></span></a></li>
<li class="chapter" data-level="9.6" data-path="mathematics-of-the-mmc.html"><a href="mathematics-of-the-mmc.html"><i class="fa fa-check"></i><b>9.6</b> Mathematics of the MMC<span></span></a></li>
<li class="chapter" data-level="9.7" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html"><i class="fa fa-check"></i><b>9.7</b> Support Vector Classifiers<span></span></a></li>
<li class="chapter" data-level="9.8" data-path="mathematics-of-the-svc.html"><a href="mathematics-of-the-svc.html"><i class="fa fa-check"></i><b>9.8</b> Mathematics of the SVC<span></span></a></li>
<li class="chapter" data-level="9.9" data-path="visual-illustration-of-svc.html"><a href="visual-illustration-of-svc.html"><i class="fa fa-check"></i><b>9.9</b> Visual Illustration of SVC<span></span></a></li>
<li class="chapter" data-level="9.10" data-path="support-vector-machines-1.html"><a href="support-vector-machines-1.html"><i class="fa fa-check"></i><b>9.10</b> Support Vector Machines<span></span></a></li>
<li class="chapter" data-level="9.11" data-path="support-vector-machines-cont..html"><a href="support-vector-machines-cont..html"><i class="fa fa-check"></i><b>9.11</b> Support Vector Machines, cont.<span></span></a></li>
<li class="chapter" data-level="9.12" data-path="radial-kernels.html"><a href="radial-kernels.html"><i class="fa fa-check"></i><b>9.12</b> Radial Kernels<span></span></a></li>
<li class="chapter" data-level="9.13" data-path="radial-kernels-cont..html"><a href="radial-kernels-cont..html"><i class="fa fa-check"></i><b>9.13</b> Radial Kernels, cont.<span></span></a></li>
<li class="chapter" data-level="9.14" data-path="svms-with-more-than-two-classes.html"><a href="svms-with-more-than-two-classes.html"><i class="fa fa-check"></i><b>9.14</b> SVMs with More than Two Classes<span></span></a></li>
<li class="chapter" data-level="9.15" data-path="lab-support-vector-classifier.html"><a href="lab-support-vector-classifier.html"><i class="fa fa-check"></i><b>9.15</b> Lab: Support Vector Classifier<span></span></a><ul>
<li class="chapter" data-level="9.15.1" data-path="lab-support-vector-classifier.html"><a href="lab-support-vector-classifier.html#tuning"><i class="fa fa-check"></i><b>9.15.1</b> Tuning<span></span></a></li>
<li class="chapter" data-level="9.15.2" data-path="lab-support-vector-classifier.html"><a href="lab-support-vector-classifier.html#linearly-separable-data"><i class="fa fa-check"></i><b>9.15.2</b> Linearly separable data<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.16" data-path="lab-support-vector-machine-non-linear-kernel.html"><a href="lab-support-vector-machine-non-linear-kernel.html"><i class="fa fa-check"></i><b>9.16</b> Lab: Support Vector Machine (non-linear kernel)<span></span></a></li>
<li class="chapter" data-level="9.17" data-path="meeting-videos-8.html"><a href="meeting-videos-8.html"><i class="fa fa-check"></i><b>9.17</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="9.17.1" data-path="meeting-videos-8.html"><a href="meeting-videos-8.html#cohort-1-8"><i class="fa fa-check"></i><b>9.17.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="9.17.2" data-path="meeting-videos-8.html"><a href="meeting-videos-8.html#cohort-2-8"><i class="fa fa-check"></i><b>9.17.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="9.17.3" data-path="meeting-videos-8.html"><a href="meeting-videos-8.html#cohort-3-8"><i class="fa fa-check"></i><b>9.17.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>10</b> Deep Learning<span></span></a><ul>
<li class="chapter" data-level="10.1" data-path="slide-1.html"><a href="slide-1.html"><i class="fa fa-check"></i><b>10.1</b> Slide 1<span></span></a></li>
<li class="chapter" data-level="10.2" data-path="slide-2.html"><a href="slide-2.html"><i class="fa fa-check"></i><b>10.2</b> Slide 2<span></span></a></li>
<li class="chapter" data-level="10.3" data-path="meeting-videos-9.html"><a href="meeting-videos-9.html"><i class="fa fa-check"></i><b>10.3</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="10.3.1" data-path="meeting-videos-9.html"><a href="meeting-videos-9.html#cohort-1-9"><i class="fa fa-check"></i><b>10.3.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="10.3.2" data-path="meeting-videos-9.html"><a href="meeting-videos-9.html#cohort-2-9"><i class="fa fa-check"></i><b>10.3.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="10.3.3" data-path="meeting-videos-9.html"><a href="meeting-videos-9.html#cohort-3-9"><i class="fa fa-check"></i><b>10.3.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html"><i class="fa fa-check"></i><b>11</b> Survival Analysis and Censored Data<span></span></a><ul>
<li class="chapter" data-level="11.1" data-path="slide-1-1.html"><a href="slide-1-1.html"><i class="fa fa-check"></i><b>11.1</b> Slide 1<span></span></a></li>
<li class="chapter" data-level="11.2" data-path="slide-2-1.html"><a href="slide-2-1.html"><i class="fa fa-check"></i><b>11.2</b> Slide 2<span></span></a></li>
<li class="chapter" data-level="11.3" data-path="meeting-videos-10.html"><a href="meeting-videos-10.html"><i class="fa fa-check"></i><b>11.3</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="11.3.1" data-path="meeting-videos-10.html"><a href="meeting-videos-10.html#cohort-1-10"><i class="fa fa-check"></i><b>11.3.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="11.3.2" data-path="meeting-videos-10.html"><a href="meeting-videos-10.html#cohort-2-10"><i class="fa fa-check"></i><b>11.3.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="11.3.3" data-path="meeting-videos-10.html"><a href="meeting-videos-10.html#cohort-3-10"><i class="fa fa-check"></i><b>11.3.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>12</b> Unsupervised Learning<span></span></a><ul>
<li class="chapter" data-level="12.1" data-path="slide-1-2.html"><a href="slide-1-2.html"><i class="fa fa-check"></i><b>12.1</b> Slide 1<span></span></a></li>
<li class="chapter" data-level="12.2" data-path="slide-2-2.html"><a href="slide-2-2.html"><i class="fa fa-check"></i><b>12.2</b> Slide 2<span></span></a></li>
<li class="chapter" data-level="12.3" data-path="meeting-videos-11.html"><a href="meeting-videos-11.html"><i class="fa fa-check"></i><b>12.3</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="12.3.1" data-path="meeting-videos-11.html"><a href="meeting-videos-11.html#cohort-1-11"><i class="fa fa-check"></i><b>12.3.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="12.3.2" data-path="meeting-videos-11.html"><a href="meeting-videos-11.html#cohort-2-11"><i class="fa fa-check"></i><b>12.3.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="12.3.3" data-path="meeting-videos-11.html"><a href="meeting-videos-11.html#cohort-3-11"><i class="fa fa-check"></i><b>12.3.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>13</b> Multiple Testing<span></span></a><ul>
<li class="chapter" data-level="13.1" data-path="slide-1-3.html"><a href="slide-1-3.html"><i class="fa fa-check"></i><b>13.1</b> Slide 1<span></span></a></li>
<li class="chapter" data-level="13.2" data-path="slide-2-3.html"><a href="slide-2-3.html"><i class="fa fa-check"></i><b>13.2</b> Slide 2<span></span></a></li>
<li class="chapter" data-level="13.3" data-path="meeting-videos-12.html"><a href="meeting-videos-12.html"><i class="fa fa-check"></i><b>13.3</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="13.3.1" data-path="meeting-videos-12.html"><a href="meeting-videos-12.html#cohort-1-12"><i class="fa fa-check"></i><b>13.3.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="13.3.2" data-path="meeting-videos-12.html"><a href="meeting-videos-12.html#cohort-2-12"><i class="fa fa-check"></i><b>13.3.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="13.3.3" data-path="meeting-videos-12.html"><a href="meeting-videos-12.html#cohort-3-12"><i class="fa fa-check"></i><b>13.3.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="abbreviations.html#abbreviations">Abbreviations<span></span></a></li>
<li><a href="latex.html#latex">Appendix: Bookdown and LaTeX Notes<span></span></a><ul>
<li><a href="markdown-highlighting.html#markdown-highlighting">Markdown highlighting<span></span></a></li>
<li><a href="text-coloring.html#text-coloring">Text coloring<span></span></a></li>
<li><a href="x99-4.html#x99-4">Section references<span></span></a></li>
<li><a href="footnotes.html#footnotes">Footnotes<span></span></a></li>
<li><a href="formatting-text.html#formatting-text">Formatting Text<span></span></a></li>
<li><a href="figures.html#figures">Figures<span></span></a></li>
<li><a href="displaying-formula.html#displaying-formula">Displaying Formula<span></span></a><ul>
<li><a href="displaying-formula.html#formatting">Formatting<span></span></a></li>
<li><a href="displaying-formula.html#symbols">Symbols<span></span></a></li>
<li><a href="displaying-formula.html#notation-1">Notation<span></span></a></li>
</ul></li>
<li><a href="equations.html#equations">Equations<span></span></a><ul>
<li><a href="equations.html#basic-equation">Basic Equation<span></span></a></li>
<li><a href="equations.html#case-when-equation-large-curly-brace">Case-When Equation (Large Curly Brace)<span></span></a></li>
<li><a href="equations.html#alligned-with-underbars">Alligned with Underbars<span></span></a></li>
</ul></li>
<li><a href="greek-letters.html#greek-letters">Greek letters<span></span></a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistical Learning Using R Book Club</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="a-comparison-of-classification-methods" class="section level2 hasAnchor">
<h2><span class="header-section-number">4.5</span> A Comparison of Classification Methods<a href="a-comparison-of-classification-methods.html#a-comparison-of-classification-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Each of the classifiers below uses different estimates of <span class="math inline">\(f_k(x)\)</span>.</p>
<ul>
<li>linear discriminant analysis;</li>
<li>quadratic discriminant analysis;</li>
<li>naive Bayes</li>
</ul>
<div id="linear-discriminant-analysis-for-p-1" class="section level3 hasAnchor">
<h3><span class="header-section-number">4.5.1</span> Linear Discriminant Analysis for p = 1<a href="a-comparison-of-classification-methods.html#linear-discriminant-analysis-for-p-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>one predictor</li>
<li>classify an observation to the class for which <span class="math inline">\(p_k(x)\)</span> is greatest</li>
</ul>
<p><strong>Assumptions:</strong>
- we assume that <span class="math inline">\(f_k(x)\)</span> is normal or Gaussian with a classs pecific
mean and,
- a shared variance term across all K classes [<span class="math inline">\(σ^2_1 = · · · = σ^2_K\)</span> ]</p>
<p>The normal density takes the form</p>
<p><span class="math display">\[f_k(x) = \frac{1}{\sqrt{2πσ_k}}exp(- \frac{1}{2σ^2_k}(x- \mu_k)^2)\]</span></p>
<p>Then, the posterior probability (probability that the observation belongs to the kth class, given the predictor value for that observation) is</p>
<p><span class="math display">\[p_k(x) = \frac{π_k \frac{1}{\sqrt{2πσ}}exp(- \frac{1}{2σ^2}(x- \mu_k)^2)}{\sum^k_{l=1} π_l \frac{1}{\sqrt{2πσ}}exp(- \frac{1}{2σ^2}(x- \mu_l)^2)}\]</span></p>
<p><strong>Additional mathematical formula</strong></p>
<p>After you log and rearrange the above equation, you will the following formula. The Bayes’ classifier assign to one class if <span class="math inline">\(2x (μ_1 − μ_2) &gt; μ_1^2 − μ_2^2\)</span> and otherwise.</p>
<p><span class="math display">\[δ_k(x) = x . \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} + log(π_k) \Longrightarrow {Equation \space 4.18}\]</span></p>
<p>The Bayes decision boundary is the point for which <span class="math inline">\(δ_1(x) = δ_2(x)\)</span></p>
<p><span class="math display">\[x = \frac{μ_1^2 − μ_2^2}{2(μ_1 − μ_2)} = \frac{μ_1 + μ_2}{2}\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig4-4"></span>
<img src="images/fig4_4.jpg" alt="Left: Two one-dimensional normal density functions are shown. The dashed vertical line represents the Bayes decision boundary. Right: 20 observations were drawn from each of the two classes, and are shown as histograms. The Bayes decision boundary is again shown as a dashed vertical line. The solid vertical line represents the LDA decision boundary estimated from the training data."  />
<p class="caption">
Figure 4.4: Left: Two one-dimensional normal density functions are shown. The dashed vertical line represents the Bayes decision boundary. Right: 20 observations were drawn from each of the two classes, and are shown as histograms. The Bayes decision boundary is again shown as a dashed vertical line. The solid vertical line represents the LDA decision boundary estimated from the training data.
</p>
</div>
<p>The <strong>linear discriminant analysis (LDA)</strong> method approximates the linear
discriminant analysis Bayes classifier by plugging estimates for <span class="math inline">\(π_k\)</span>, <span class="math inline">\(μ_k\)</span>, and <span class="math inline">\(σ^2\)</span> into equation 4.18.</p>
<p><span class="math inline">\(\hat μ_k\)</span> is the average of all the training observations from the kth class
<span class="math display">\[\hat{\mu}_{k} = \frac{1}{n_{k}}\sum_{i: y_{i}= k} x_{i}\]</span></p>
<p><span class="math inline">\(\hat σ^2\)</span> is the weighted average of the sample variances for each of the K classes</p>
<p><span class="math display">\[\hat{\sigma}^2 = \frac{1}{n - K} \sum_{k = 1}^{K} \sum_{i: y_{i}= k} (x_{i} - \hat{\mu}_{k})^2\]</span></p>
<p>Note.
n = total number of training observations,
<span class="math inline">\(n_k\)</span> = number of training observations in the kth class</p>
<p><span class="math inline">\(π_k\)</span> is estimated from the proportion of the training observations
that belong to the kth class.</p>
<p><span class="math display">\[π_k = \frac{n_k}{n}\]</span></p>
<p>LDA classifier assigns an observation X = x to the class for which <span class="math inline">\(δ_k(x)\)</span> is largest.</p>
<p><span class="math display">\[δ_k(x) = x . \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} + log(π_k) \Longrightarrow {Equation \space 4.18} \\ \Downarrow \\ \hat δ_k(x) = x \cdot \frac{\hat \mu_k}{\hat \sigma^2} - \frac{\hat \mu_k^2}{2\hat \sigma^2} + log(\hat π_k)\]</span></p>
</div>
<div id="linear-discriminant-analysis-for-p-1-1" class="section level3 hasAnchor">
<h3><span class="header-section-number">4.5.2</span> Linear Discriminant Analysis for p &gt; 1<a href="a-comparison-of-classification-methods.html#linear-discriminant-analysis-for-p-1-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>multiple predictors; p &gt; 1 predictors</p></li>
<li><p>observations come from a multivariate Gaussian (or multivariate normal) distribution, with a <strong>class-specific mean vector</strong> and a common <strong>covariance matrix</strong>; <span class="math display">\[N(μ_k,Σ)\]</span></p></li>
</ul>
<p><strong>Assumptions: </strong>
- each individual predictor follows a one-dimensional normal distribution, with predictors having some correlation</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig4-5"></span>
<img src="images/fig4_5.jpg" alt="Two multivariate Gaussian density functions are shown, with p = 2. Left: The two predictors are uncorrelated and it has a circular base. Var(X_1) = Var(X_2) and Cor(X_1,X_2) = 0; Right: The two variables have a correlation of 0.7 with a elliptical base"  />
<p class="caption">
Figure 4.5: Two multivariate Gaussian density functions are shown, with p = 2. Left: The two predictors are uncorrelated and it has a circular base. Var(X_1) = Var(X_2) and Cor(X_1,X_2) = 0; Right: The two variables have a correlation of 0.7 with a elliptical base
</p>
</div>
<p><span class="math inline">\(\exp\)</span>
The multivariate Gaussian density is defined as:</p>
<p><span class="math display">\[f(x) = \frac{1}{(2π)^{\frac{p}{2}}|Σ|^{\frac{1}{2}}}\exp -\frac{1}{2}(x - \mu)^T Σ^{−1}(x − μ))\]</span></p>
<p>Bayes classifier assigns an observation X = x to the class for which <span class="math display">\[δ_k(x)\]</span> is largest.</p>
<p><span class="math display">\[δ_k(x) =  x^T Σ^{−1}μ_k - \frac{1}{2}μ_k^T Σ^{−1} μ_k + log π_k \Longrightarrow vector/matrix \space version \\ δ_k(x) = x . \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} + log(π_k) \Longrightarrow {Equation \space 4.18}\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig4-6"></span>
<img src="images/fig4_6.jpg" alt="An example with three classes. The observations from each class are drawn from a multivariate Gaussian distribution with p = 2, with a class-specific mean vector and a common covariance matrix. Left: Ellipses that contain 95% of the probability for each of the three classes are shown. The dashed lines are the Bayes decision boundaries. Right: 20 observations were generated from each class, and the corresponding LDA decision boundaries are indicated using solid black lines. The Bayes decision boundaries are once again shown as dashed lines. Overall, the LDA decision boundaries are pretty close to the Bayes decision boundaries, shown again as dashed lines. The test error rates for the Bayes and LDA classifiers are 0.0746 and 0.0770, respectively."  />
<p class="caption">
Figure 4.6: An example with three classes. The observations from each class are drawn from a multivariate Gaussian distribution with p = 2, with a class-specific mean vector and a common covariance matrix. Left: Ellipses that contain 95% of the probability for each of the three classes are shown. The dashed lines are the Bayes decision boundaries. Right: 20 observations were generated from each class, and the corresponding LDA decision boundaries are indicated using solid black lines. The Bayes decision boundaries are once again shown as dashed lines. Overall, the LDA decision boundaries are pretty close to the Bayes decision boundaries, shown again as dashed lines. The test error rates for the Bayes and LDA classifiers are 0.0746 and 0.0770, respectively.
</p>
</div>
<p>All classification models have training error rate, which can be displayed with a <strong>confusion matrix</strong>.</p>
<p><strong>Caveats of error rate: </strong></p>
<ul>
<li><p>training error rates will usually be lower than test error rates, which are the real quantity of interest. The higher the ratio of parameters <em>p</em> to number of samples n, the more we expect this <em>overfitting</em> to play a role.</p></li>
<li><p>the trivial null classifier will achieve an error rate that is only a bit higher than the LDA training set error rate</p></li>
<li><p>a binary classifier such as this one can make two types of errors (Type I and II)</p></li>
<li><p>Class-specific performance <em>(sensitivity and specificity)</em> is important in certain fields (e.g., medicine)</p></li>
</ul>
<p>LDA has low sensitivity due to
1. LDA is trying to approximate the Bayes classifier, which has the lowest
total error rate out of all classifiers
2. In the process, the Bayes classifier will yield the smallest possible total number of misclassified observations, regardless of the class from which the errors stem.
3. It also uses a threshold of 50% for the posterior probability of default in order to assign an observation to the default class</p>
<p><span class="math display">\[Pr(default = Yes|X = x) &gt; 0.5. \\ Pr(default = Yes|X = x) &gt; 0.2.\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig4-7"></span>
<img src="images/fig4_7.jpg" alt="The figure illustrates the trade-off that results from modifying the threshold value for the posterior probability of default. For the Default data set, error rates are shown as a function of the threshold value for the posterior probability that is used to perform the assignment. The black solid line displays the overall error rate. The blue dashed line represents the fraction of defaulting customers that are incorrectly classified, and the orange dotted line indicates the fraction of errors among the non-defaulting customers."  />
<p class="caption">
Figure 4.7: The figure illustrates the trade-off that results from modifying the threshold value for the posterior probability of default. For the Default data set, error rates are shown as a function of the threshold value for the posterior probability that is used to perform the assignment. The black solid line displays the overall error rate. The blue dashed line represents the fraction of defaulting customers that are incorrectly classified, and the orange dotted line indicates the fraction of errors among the non-defaulting customers.
</p>
</div>
<ul>
<li><p>As the threshold is reduced, the error rate among individuals who default decreases steadily, but the error rate among the individuals who do not default increases. The decision on the threshold must be based on <strong>domain knowledge</strong> (e.g., detailed information about the costs associated with default)</p></li>
<li><p>ROC curve is a way to illustrate the two type of errors at all possible thresholds.</p></li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig4-8"></span>
<img src="images/fig4_8.jpg" alt="The true positive rate is the sensitivity: the fraction of defaulters that are correctly identified, using a given threshold value. The false positive rate is 1-specificity: the fraction of non-defaulters that we classify incorrectly as defaulters, using that same threshold value. The ideal ROC curve hugs the top left corner, indicating a high true positive rate and a low false positive rate. The dotted line represents the “no information” classifier; this is what we would expect if student status and credit card balance are not associated with probability of default."  />
<p class="caption">
Figure 4.8: The true positive rate is the sensitivity: the fraction of defaulters that are correctly identified, using a given threshold value. The false positive rate is 1-specificity: the fraction of non-defaulters that we classify incorrectly as defaulters, using that same threshold value. The ideal ROC curve hugs the top left corner, indicating a high true positive rate and a low false positive rate. The dotted line represents the “no information” classifier; this is what we would expect if student status and credit card balance are not associated with probability of default.
</p>
</div>
<p>An ideal ROC curve will hug the top left corner, so the larger <strong>area under the ROC curve (AUC)</strong>, the better the classifier.</p>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<th style="border-top: 2px solid grey;">
</th>
<th colspan="3" style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
True class
</th>
</tr>
<tr>
<th style="border-bottom: 1px solid grey;">
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; text-align: center;">
Neg. or Null
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; text-align: center;">
Pos. or Non-null
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; text-align: center;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="4" style="font-weight: 900;">
Predicted class
</td>
</tr>
<tr>
<td style="text-align: left;">
   − or Null
</td>
<td style="text-align: left;">
True Neg. (TN)
</td>
<td style="text-align: center;">
False Neg. (FN)
</td>
<td style="text-align: right;">
N∗
</td>
</tr>
<tr>
<td style="text-align: left;">
   + or Non-null
</td>
<td style="text-align: left;">
False Pos. (FP)
</td>
<td style="text-align: center;">
True Pos. (TP)
</td>
<td style="text-align: right;">
P∗
</td>
</tr>
<tr>
<td style="border-bottom: 2px solid grey; text-align: left;">
  Total
</td>
<td style="border-bottom: 2px solid grey; text-align: left;">
N
</td>
<td style="border-bottom: 2px solid grey; text-align: center;">
P
</td>
<td style="border-bottom: 2px solid grey; text-align: right;">
</td>
</tr>
</tbody>
</table>
<p>Important measures for classification and diagnostic testing:</p>
<ul>
<li><p><strong>False Positive rate (FP/N)</strong> <span class="math inline">\(\Longrightarrow\)</span> Type I error, 1−Specificity</p></li>
<li><p><strong>True Positive rate (TP/P)</strong> <span class="math inline">\(\Longrightarrow\)</span> 1−Type II error, power, sensitivity, recall</p></li>
<li><p><strong>Pos. Predicted value (TP/P∗)</strong> <span class="math inline">\(\Longrightarrow\)</span> Precision, 1−false discovery proportion</p></li>
<li><p><strong>Neg. Predicted value (TN/N∗)</strong></p></li>
</ul>
</div>
<div id="quadratic-discriminant-analysis-qda" class="section level3 hasAnchor">
<h3><span class="header-section-number">4.5.3</span> Quadratic Discriminant Analysis (QDA)<a href="a-comparison-of-classification-methods.html#quadratic-discriminant-analysis-qda" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Assumptions similar to LDA, in which observations from each class are drawn from a Gaussian distribution, and plugging estimates for the parameters into Bayes’ theorem in order to perform prediction</p></li>
<li><p>QDA assumes that each class has its own covariance matrix</p></li>
</ul>
<p><span class="math display">\[X ∼ N(μ_k,Σ_k) \Longrightarrow {Σ_k is \space covariance \space matrix \space for \space the \space kth \space class}\]</span></p>
<p><strong>Bayes classifier</strong></p>
<p><span class="math display">\[δ_k(x) = - \frac{1}{2}(x - \mu_k)^T Σ_k^{−1}(x - \mu_k) - \frac{1}{2}log|Σ_k| + log(π_k) \\ \Downarrow \\ δ_k(x) =  - \frac{1}{2}x^T Σ_k^{−1}x - x^T Σ_k^{−1} \mu_k - \frac{1}{2}μ_k^T Σ_k^{−1} μ_k - \frac{1}{2}log|Σ_k| + log π_k\]</span></p>
<p>QDA classifier involves plugging estimates for <strong><span class="math inline">\(Σ_k\)</span>, <span class="math inline">\(μ_k\)</span>, and <span class="math inline">\(π_k\)</span></strong> into the above equation, and then assigning an observation X = x to the class for which this quantity is <strong>largest</strong>.</p>
<p>The quantity x appears as a quadratic function, hence the name.</p>
<p><br>
<strong>Why the LDA to QDA is preferred or vice-versa?</strong>
<br>
1. <strong>Bias-variance trade-off</strong>
<br>
- Pro LDA: LDA assumes that the K classes share a common covariance matrix and the quantity X becomes linear, which means there are <span class="math inline">\(K_p\)</span> linear coefficients to estimate.LDA is a much less flexible classifier than QDA, and so has substantially <em>lower variance</em>; improved prediction performance.</p>
<ul>
<li><p>Con LDA: If the assumption K classes share a common covariance matrix is badly off, LDA can suffer from <em>high bias</em></p></li>
<li><p>Conclusion: Use LDA when there is a few training observations; use QDA when the training set is very large or common covariance matrix is untennable.</p></li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig4-9"></span>
<img src="images/fig4_9.jpg" alt="Left: The Bayes (purple dashed), LDA (black dotted), and QDA (green solid) decision boundaries for a two-class problem with Σ1 = Σ2. The shading indicates the QDA decision rule. Since the Bayes decision boundary is linear, it is more accurately approximated by LDA than by QDA. Right: Details are as given in the left-hand panel, except that Σ1 ̸= Σ2. Since the Bayes decision boundary is non-linear, it is more accurately approximated by QDA than by LDA."  />
<p class="caption">
Figure 4.9: Left: The Bayes (purple dashed), LDA (black dotted), and QDA (green solid) decision boundaries for a two-class problem with Σ1 = Σ2. The shading indicates the QDA decision rule. Since the Bayes decision boundary is linear, it is more accurately approximated by LDA than by QDA. Right: Details are as given in the left-hand panel, except that Σ1 ̸= Σ2. Since the Bayes decision boundary is non-linear, it is more accurately approximated by QDA than by LDA.
</p>
</div>
</div>
<div id="naive-bayes" class="section level3 hasAnchor">
<h3><span class="header-section-number">4.5.4</span> Naive Bayes<a href="a-comparison-of-classification-methods.html#naive-bayes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Estimating a p-dimensional density function is challenging; naive bayes make a different assumption than LDA and QDA.</li>
<li>an alternative to LDA that does not assume normally distributed
predictors</li>
</ul>
<p><span class="math display">\[f_k(x) = f_{k1}(x_1) × f_{k2}(x_2)×· · ·×f{k_p}(x_p),\]</span>
where <span class="math inline">\(f_{kj}\)</span> is the density function of the jth predictor among observations in the kth class</p>
<p><em>Within the kth class, the p predictors are independent.</em></p>
<p><strong>Why naive Bayes is better/powerful?</strong></p>
<ol style="list-style-type: decimal">
<li><p>By assuming that the p covariates are independent within each class, we assumed that there is no association between the predictors! When estimating a p-dimensional density function, it is difficult to calculate the <em>marginal distribution</em> of each predictor and <em>joint distribution</em> of the predictors.</p></li>
<li><p>Although p covariates might not be independent within each class, it is convenient and we obtain pretty decent results when the n is small, p is large.</p></li>
<li><p>It reduces variance, though it has some bias (Bias-variance trade-off)</p></li>
</ol>
<p><strong>Options to estimate the one-dimensional density function fkj using training data</strong></p>
<ol style="list-style-type: decimal">
<li><p>[For Quantitative <span class="math inline">\(X_j\)</span>] -&gt; We assume <span class="math inline">\(X_j |Y = k ∼ N(μ_{jk},σ_{jk}^2)\)</span>, where within each class, the jth predictor is drawn from a (univariate) normal distribution. It is <strong>QDA-like with diagonal class-specific covariance matrix</strong></p></li>
<li><p>[For Quantitative <span class="math inline">\(X_j\)</span>] -&gt; Use a <em>non-parametric estimate</em> for <span class="math inline">\(f_{kj}\)</span>. First, a histogram for the within-class observations and then estimate <span class="math inline">\(f_{kj}(x_j)\)</span>. Or else, use <strong>kernel density estimator</strong>.</p></li>
<li><p>[For Qualitative <span class="math inline">\(X_j\)</span>] -&gt;Count the proportion of training observations for the jth predictor corresponding to each class.</p></li>
</ol>
<p>Note: Fixing the threshold, the Naive Bayes has a higher error rate than LDA, but better prediction (higher sensitivity).</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generative-models-for-classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary-of-the-classification-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/r4ds/bookclub-islr/edit/main/04.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
